{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Classification_NADACorpus",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmeenReda1/Text_classification_NADACorpus/blob/main/Text_Classification_NADACorpus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iVsr9ibmeeC"
      },
      "source": [
        "#Text_Classification_NADACorpus\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV22VM2WjNGa"
      },
      "source": [
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm,preprocessing,metrics"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "fO4fwnycVSzx",
        "outputId": "2e887e48-ad16-4a5c-e6c6-fcb823d8bce3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNbdra3ujSJe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d363397f-9ca5-4177-bbfb-6631b5d3eb49"
      },
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "dataFrame=pd.read_csv('/content/drive/MyDrive/Sampled_File_with_SMOTE.csv')\n",
        "stop=stopwords.words('arabic')\n",
        "print(stop)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['إذ', 'إذا', 'إذما', 'إذن', 'أف', 'أقل', 'أكثر', 'ألا', 'إلا', 'التي', 'الذي', 'الذين', 'اللاتي', 'اللائي', 'اللتان', 'اللتيا', 'اللتين', 'اللذان', 'اللذين', 'اللواتي', 'إلى', 'إليك', 'إليكم', 'إليكما', 'إليكن', 'أم', 'أما', 'أما', 'إما', 'أن', 'إن', 'إنا', 'أنا', 'أنت', 'أنتم', 'أنتما', 'أنتن', 'إنما', 'إنه', 'أنى', 'أنى', 'آه', 'آها', 'أو', 'أولاء', 'أولئك', 'أوه', 'آي', 'أي', 'أيها', 'إي', 'أين', 'أين', 'أينما', 'إيه', 'بخ', 'بس', 'بعد', 'بعض', 'بك', 'بكم', 'بكم', 'بكما', 'بكن', 'بل', 'بلى', 'بما', 'بماذا', 'بمن', 'بنا', 'به', 'بها', 'بهم', 'بهما', 'بهن', 'بي', 'بين', 'بيد', 'تلك', 'تلكم', 'تلكما', 'ته', 'تي', 'تين', 'تينك', 'ثم', 'ثمة', 'حاشا', 'حبذا', 'حتى', 'حيث', 'حيثما', 'حين', 'خلا', 'دون', 'ذا', 'ذات', 'ذاك', 'ذان', 'ذانك', 'ذلك', 'ذلكم', 'ذلكما', 'ذلكن', 'ذه', 'ذو', 'ذوا', 'ذواتا', 'ذواتي', 'ذي', 'ذين', 'ذينك', 'ريث', 'سوف', 'سوى', 'شتان', 'عدا', 'عسى', 'عل', 'على', 'عليك', 'عليه', 'عما', 'عن', 'عند', 'غير', 'فإذا', 'فإن', 'فلا', 'فمن', 'في', 'فيم', 'فيما', 'فيه', 'فيها', 'قد', 'كأن', 'كأنما', 'كأي', 'كأين', 'كذا', 'كذلك', 'كل', 'كلا', 'كلاهما', 'كلتا', 'كلما', 'كليكما', 'كليهما', 'كم', 'كم', 'كما', 'كي', 'كيت', 'كيف', 'كيفما', 'لا', 'لاسيما', 'لدى', 'لست', 'لستم', 'لستما', 'لستن', 'لسن', 'لسنا', 'لعل', 'لك', 'لكم', 'لكما', 'لكن', 'لكنما', 'لكي', 'لكيلا', 'لم', 'لما', 'لن', 'لنا', 'له', 'لها', 'لهم', 'لهما', 'لهن', 'لو', 'لولا', 'لوما', 'لي', 'لئن', 'ليت', 'ليس', 'ليسا', 'ليست', 'ليستا', 'ليسوا', 'ما', 'ماذا', 'متى', 'مذ', 'مع', 'مما', 'ممن', 'من', 'منه', 'منها', 'منذ', 'مه', 'مهما', 'نحن', 'نحو', 'نعم', 'ها', 'هاتان', 'هاته', 'هاتي', 'هاتين', 'هاك', 'هاهنا', 'هذا', 'هذان', 'هذه', 'هذي', 'هذين', 'هكذا', 'هل', 'هلا', 'هم', 'هما', 'هن', 'هنا', 'هناك', 'هنالك', 'هو', 'هؤلاء', 'هي', 'هيا', 'هيت', 'هيهات', 'والذي', 'والذين', 'وإذ', 'وإذا', 'وإن', 'ولا', 'ولكن', 'ولو', 'وما', 'ومن', 'وهو', 'يا', 'أبٌ', 'أخٌ', 'حمٌ', 'فو', 'أنتِ', 'يناير', 'فبراير', 'مارس', 'أبريل', 'مايو', 'يونيو', 'يوليو', 'أغسطس', 'سبتمبر', 'أكتوبر', 'نوفمبر', 'ديسمبر', 'جانفي', 'فيفري', 'مارس', 'أفريل', 'ماي', 'جوان', 'جويلية', 'أوت', 'كانون', 'شباط', 'آذار', 'نيسان', 'أيار', 'حزيران', 'تموز', 'آب', 'أيلول', 'تشرين', 'دولار', 'دينار', 'ريال', 'درهم', 'ليرة', 'جنيه', 'قرش', 'مليم', 'فلس', 'هللة', 'سنتيم', 'يورو', 'ين', 'يوان', 'شيكل', 'واحد', 'اثنان', 'ثلاثة', 'أربعة', 'خمسة', 'ستة', 'سبعة', 'ثمانية', 'تسعة', 'عشرة', 'أحد', 'اثنا', 'اثني', 'إحدى', 'ثلاث', 'أربع', 'خمس', 'ست', 'سبع', 'ثماني', 'تسع', 'عشر', 'ثمان', 'سبت', 'أحد', 'اثنين', 'ثلاثاء', 'أربعاء', 'خميس', 'جمعة', 'أول', 'ثان', 'ثاني', 'ثالث', 'رابع', 'خامس', 'سادس', 'سابع', 'ثامن', 'تاسع', 'عاشر', 'حادي', 'أ', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ي', 'ء', 'ى', 'آ', 'ؤ', 'ئ', 'أ', 'ة', 'ألف', 'باء', 'تاء', 'ثاء', 'جيم', 'حاء', 'خاء', 'دال', 'ذال', 'راء', 'زاي', 'سين', 'شين', 'صاد', 'ضاد', 'طاء', 'ظاء', 'عين', 'غين', 'فاء', 'قاف', 'كاف', 'لام', 'ميم', 'نون', 'هاء', 'واو', 'ياء', 'همزة', 'ي', 'نا', 'ك', 'كن', 'ه', 'إياه', 'إياها', 'إياهما', 'إياهم', 'إياهن', 'إياك', 'إياكما', 'إياكم', 'إياك', 'إياكن', 'إياي', 'إيانا', 'أولالك', 'تانِ', 'تانِك', 'تِه', 'تِي', 'تَيْنِ', 'ثمّ', 'ثمّة', 'ذانِ', 'ذِه', 'ذِي', 'ذَيْنِ', 'هَؤلاء', 'هَاتانِ', 'هَاتِه', 'هَاتِي', 'هَاتَيْنِ', 'هَذا', 'هَذانِ', 'هَذِه', 'هَذِي', 'هَذَيْنِ', 'الألى', 'الألاء', 'أل', 'أنّى', 'أيّ', 'ّأيّان', 'أنّى', 'أيّ', 'ّأيّان', 'ذيت', 'كأيّ', 'كأيّن', 'بضع', 'فلان', 'وا', 'آمينَ', 'آهِ', 'آهٍ', 'آهاً', 'أُفٍّ', 'أُفٍّ', 'أفٍّ', 'أمامك', 'أمامكَ', 'أوّهْ', 'إلَيْكَ', 'إلَيْكَ', 'إليكَ', 'إليكنّ', 'إيهٍ', 'بخٍ', 'بسّ', 'بَسْ', 'بطآن', 'بَلْهَ', 'حاي', 'حَذارِ', 'حيَّ', 'حيَّ', 'دونك', 'رويدك', 'سرعان', 'شتانَ', 'شَتَّانَ', 'صهْ', 'صهٍ', 'طاق', 'طَق', 'عَدَسْ', 'كِخ', 'مكانَك', 'مكانَك', 'مكانَك', 'مكانكم', 'مكانكما', 'مكانكنّ', 'نَخْ', 'هاكَ', 'هَجْ', 'هلم', 'هيّا', 'هَيْهات', 'وا', 'واهاً', 'وراءَك', 'وُشْكَانَ', 'وَيْ', 'يفعلان', 'تفعلان', 'يفعلون', 'تفعلون', 'تفعلين', 'اتخذ', 'ألفى', 'تخذ', 'ترك', 'تعلَّم', 'جعل', 'حجا', 'حبيب', 'خال', 'حسب', 'خال', 'درى', 'رأى', 'زعم', 'صبر', 'ظنَّ', 'عدَّ', 'علم', 'غادر', 'ذهب', 'وجد', 'ورد', 'وهب', 'أسكن', 'أطعم', 'أعطى', 'رزق', 'زود', 'سقى', 'كسا', 'أخبر', 'أرى', 'أعلم', 'أنبأ', 'حدَث', 'خبَّر', 'نبَّا', 'أفعل به', 'ما أفعله', 'بئس', 'ساء', 'طالما', 'قلما', 'لات', 'لكنَّ', 'ءَ', 'أجل', 'إذاً', 'أمّا', 'إمّا', 'إنَّ', 'أنًّ', 'أى', 'إى', 'أيا', 'ب', 'ثمَّ', 'جلل', 'جير', 'رُبَّ', 'س', 'علًّ', 'ف', 'كأنّ', 'كلَّا', 'كى', 'ل', 'لات', 'لعلَّ', 'لكنَّ', 'لكنَّ', 'م', 'نَّ', 'هلّا', 'وا', 'أل', 'إلّا', 'ت', 'ك', 'لمّا', 'ن', 'ه', 'و', 'ا', 'ي', 'تجاه', 'تلقاء', 'جميع', 'حسب', 'سبحان', 'شبه', 'لعمر', 'مثل', 'معاذ', 'أبو', 'أخو', 'حمو', 'فو', 'مئة', 'مئتان', 'ثلاثمئة', 'أربعمئة', 'خمسمئة', 'ستمئة', 'سبعمئة', 'ثمنمئة', 'تسعمئة', 'مائة', 'ثلاثمائة', 'أربعمائة', 'خمسمائة', 'ستمائة', 'سبعمائة', 'ثمانمئة', 'تسعمائة', 'عشرون', 'ثلاثون', 'اربعون', 'خمسون', 'ستون', 'سبعون', 'ثمانون', 'تسعون', 'عشرين', 'ثلاثين', 'اربعين', 'خمسين', 'ستين', 'سبعين', 'ثمانين', 'تسعين', 'بضع', 'نيف', 'أجمع', 'جميع', 'عامة', 'عين', 'نفس', 'لا سيما', 'أصلا', 'أهلا', 'أيضا', 'بؤسا', 'بعدا', 'بغتة', 'تعسا', 'حقا', 'حمدا', 'خلافا', 'خاصة', 'دواليك', 'سحقا', 'سرا', 'سمعا', 'صبرا', 'صدقا', 'صراحة', 'طرا', 'عجبا', 'عيانا', 'غالبا', 'فرادى', 'فضلا', 'قاطبة', 'كثيرا', 'لبيك', 'معاذ', 'أبدا', 'إزاء', 'أصلا', 'الآن', 'أمد', 'أمس', 'آنفا', 'آناء', 'أنّى', 'أول', 'أيّان', 'تارة', 'ثمّ', 'ثمّة', 'حقا', 'صباح', 'مساء', 'ضحوة', 'عوض', 'غدا', 'غداة', 'قطّ', 'كلّما', 'لدن', 'لمّا', 'مرّة', 'قبل', 'خلف', 'أمام', 'فوق', 'تحت', 'يمين', 'شمال', 'ارتدّ', 'استحال', 'أصبح', 'أضحى', 'آض', 'أمسى', 'انقلب', 'بات', 'تبدّل', 'تحوّل', 'حار', 'رجع', 'راح', 'صار', 'ظلّ', 'عاد', 'غدا', 'كان', 'ما انفك', 'ما برح', 'مادام', 'مازال', 'مافتئ', 'ابتدأ', 'أخذ', 'اخلولق', 'أقبل', 'انبرى', 'أنشأ', 'أوشك', 'جعل', 'حرى', 'شرع', 'طفق', 'علق', 'قام', 'كرب', 'كاد', 'هبّ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean(text):\n",
        "  #remove all English chars \n",
        "  text = re.sub(r'\\s*[A-Za-z]\\s*', ' ' , text)\n",
        "  #remove hashtags\n",
        "  text = re.sub(\"#\", \" \", text)\n",
        "  #remove all numbers \n",
        "  text = re.sub(r'\\[0-9]*\\]',' ',text)\n",
        "  #remove duplicated chars\n",
        "  text = re.sub(r'(.)\\1+', r'\\1', text)\n",
        "  #remove :) or :(\n",
        "  text = text.replace(':)', \"\")\n",
        "  text = text.replace(':(', \"\")\n",
        "  #remove multiple exclamation\n",
        "  text = re.sub(r\"(\\!)\\1+\", ' ', text)\n",
        "  #remove multiple question marks\n",
        "  text = re.sub(r\"(\\?)\\1+\", ' ', text)\n",
        "  #remove multistop\n",
        "  text = re.sub(r\"(\\.)\\1+\", ' ', text)\n",
        "  #remove additional spaces\n",
        "  text = re.sub(r\"[\\s]+\", \" \", text)\n",
        "  text = re.sub(r\"[\\n]+\", \" \", text)\n",
        "  \n",
        "  return text"
      ],
      "metadata": {
        "id": "ByBVxekccAj6"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "from nltk.stem.isri import ISRIStemmer\n",
        "st = ISRIStemmer()"
      ],
      "metadata": {
        "id": "CEKNufeHchOP"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "stopWordsList = stopwords.words('arabic')\n",
        "dataFrame['text']=dataFrame['text'].apply(lambda line: \" \".join(word for word in line.split() if word not in stop))\n",
        "dataFrame['text'] = dataFrame['text'].apply(lambda x : clean(x))\n",
        "dataFrame['text']=dataFrame['text'].apply(lambda line: \" \".join(st.stem(word) for word in line.split()))"
      ],
      "metadata": {
        "id": "fBKYObfJcQg-",
        "outputId": "2c17cc1e-8b48-4056-ec53-f053b263b41e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    'غلب اصل عمل قرب رحب خصر لدن نخل تد قرب حصل فا...\n",
            "1    'اضاف اخر بنك دول مال رئس عمل قلص افق قاذ تحر ...\n",
            "2    'مستقر ضفت اخر دول تفق عمل قلص افق قاذ رحب كبر...\n",
            "3    'اوسط سرق بنك عما تحد خبر لمل فضل سير راديو اخ...\n",
            "4    'اوسط اطل عما تحد بان خبر لمل عمل راديو اخر خت...\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fC-FcI0-cZkH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFwKrhZVkJ4L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bf4ce97-14b7-4e5c-db00-e3ee00dcdae7"
      },
      "source": [
        "print(dataFrame.head())\n",
        "print(len(dataFrame['text']))\n",
        "dataFrame.drop_duplicates(subset =\"text\",\n",
        "                     keep = 'first', inplace = True)\n",
        "print(len(dataFrame['text']))\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text                     class\n",
            "0  'غلب اصل عمل قرب رحب خصر لدن نخل تد قرب حصل فا...  'الإقتصاد-علوم اجتماعية'\n",
            "1  'اضاف اخر بنك دول مال رئس عمل قلص افق قاذ تحر ...  'الإقتصاد-علوم اجتماعية'\n",
            "2  'مستقر ضفت اخر دول تفق عمل قلص افق قاذ رحب كبر...  'الإقتصاد-علوم اجتماعية'\n",
            "3  'اوسط سرق بنك عما تحد خبر لمل فضل سير راديو اخ...  'الإقتصاد-علوم اجتماعية'\n",
            "4  'اوسط اطل عما تحد بان خبر لمل عمل راديو اخر خت...  'الإقتصاد-علوم اجتماعية'\n",
            "5745\n",
            "5745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FpHx97akNlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bd250c9-b9d2-435d-c8fe-898dd3f59571"
      },
      "source": [
        "train_x, valid_x, train_y, valid_y = train_test_split(dataFrame['text'], dataFrame['class'],test_size=0.2,random_state=11)\n",
        "print(len(set(train_y)))\n",
        "print(len(set(valid_y)))\n",
        "before_encode_valid_y=dataFrame['class'].unique()\n",
        "print('before_encode: ',before_encode_valid_y)\n",
        "# TFIDF feature generation for a maximum of 5000 features\n",
        "print(\"vaild X\",valid_x.head())\n",
        "print(\"vaild X\",valid_y.head())\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word',token_pattern=r'\\w{1,}', max_features=5000)\n",
        "print(tfidf_vect)\n",
        "tfidf_vect.fit(dataFrame['text'])\n",
        "xtrain_tfidf = tfidf_vect.transform(train_x)\n",
        "xvalid_tfidf = tfidf_vect.transform(valid_x)\n",
        "print(xtrain_tfidf.data)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "10\n",
            "before_encode:  [\"'الإقتصاد-علوم اجتماعية'\" \"'الأدب العربي-أدبيات'\" 'رياضة'\n",
            " \"'علوم صحية-علوم تطبيقية'\" \"'السياسة-علوم اجتماعية'\"\n",
            " \"'القانون-علوم اجتماعية'\" 'عام-اسلام-ديانات' \"'علم الكمبيوتر-علوم بحتة'\"\n",
            " \"'عام- فنون'\" \"'فلك-علوم بحتة'\"]\n",
            "vaild X 4026    'يستعد فن فاد دروس طلق بوم قرب خرج ستر كاديم س...\n",
            "1268    'يم قول بان صندوق نقد انت ظيف عام وقف حكم امر ...\n",
            "614     'استخدام قئم دب تقت جلز ادئ محل وير خط لفت رحل...\n",
            "800     'اوسط توج عطل خسر عكس رئس سوق بدا عمل كتوبر را...\n",
            "2360    'عقد لجن فن بطل نخب خلج لمب قام حال قطر جمع حد...\n",
            "Name: text, dtype: object\n",
            "vaild X 4026                 'عام- فنون'\n",
            "1268    'الإقتصاد-علوم اجتماعية'\n",
            "614     'الإقتصاد-علوم اجتماعية'\n",
            "800     'الإقتصاد-علوم اجتماعية'\n",
            "2360                       رياضة\n",
            "Name: class, dtype: object\n",
            "TfidfVectorizer(max_features=5000, token_pattern='\\\\w{1,}')\n",
            "[0.03816784 0.04793851 0.07045268 ... 0.04032139 0.02154145 0.03207037]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmsBVwGokQrx"
      },
      "source": [
        "def train_model(classifier, feature_vector_train, label,feature_vector_valid, is_neural_net=False):\n",
        "    # fit the training dataset on the classifier\n",
        "    classifier.fit(feature_vector_train, label)\n",
        "    # predict the labels on validation dataset\n",
        "    predictions = classifier.predict(feature_vector_valid)\n",
        "    return metrics.accuracy_score(predictions, valid_y),predictions"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM Model"
      ],
      "metadata": {
        "id": "iafk8R_9XJ33"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2NvOFoNkTx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf75442b-262d-4965-dcea-07a669f79883"
      },
      "source": [
        "clf_svm = svm.SVC(kernel='linear')\n",
        "#train_model\n",
        "accuracy,predictions=train_model(clf_svm,xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print(\"accuracy: \",accuracy*100)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  97.56309834638816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(classification_report(valid_y,predictions))"
      ],
      "metadata": {
        "id": "fzYK488yZ0YP",
        "outputId": "3679cf43-329e-4aac-eaa7-bfdfe1d6a629",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97        58\n",
            "           1       0.97      0.99      0.98       275\n",
            "           2       1.00      0.73      0.85        30\n",
            "           3       0.95      0.99      0.97       253\n",
            "           4       1.00      1.00      1.00        54\n",
            "           5       0.97      0.95      0.96        64\n",
            "           6       0.98      1.00      0.99        62\n",
            "           7       1.00      1.00      1.00        50\n",
            "           8       1.00      0.99      1.00       198\n",
            "           9       0.97      0.93      0.95       105\n",
            "\n",
            "    accuracy                           0.98      1149\n",
            "   macro avg       0.98      0.96      0.97      1149\n",
            "weighted avg       0.98      0.98      0.98      1149\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN model"
      ],
      "metadata": {
        "id": "yLghZQPiX3IX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "accuracy,predictions=train_model(knn_model,xtrain_tfidf,train_y,xvalid_tfidf)\n",
        "print(\"KNN accuracy: \",accuracy*100)"
      ],
      "metadata": {
        "id": "No645vTGXSGD",
        "outputId": "5ca19154-e4a8-4769-b608-3dfc3d17e49a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN accuracy:  93.73368146214099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Hns-gzgkYeE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa49aceb-66e5-4fb5-c169-67cb80014731"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(classification_report(valid_y,predictions))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.95      0.88        58\n",
            "           1       0.94      0.96      0.95       275\n",
            "           2       0.86      0.63      0.73        30\n",
            "           3       0.90      0.98      0.94       253\n",
            "           4       0.96      0.98      0.97        54\n",
            "           5       0.90      0.88      0.89        64\n",
            "           6       1.00      0.98      0.99        62\n",
            "           7       0.94      1.00      0.97        50\n",
            "           8       0.99      0.96      0.98       198\n",
            "           9       0.98      0.76      0.86       105\n",
            "\n",
            "    accuracy                           0.94      1149\n",
            "   macro avg       0.93      0.91      0.92      1149\n",
            "weighted avg       0.94      0.94      0.94      1149\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "K1dVUG-va5Al"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZMLjGjoNiq8",
        "outputId": "7285639f-e583-455a-8156-35da2c81b557"
      },
      "source": [
        "import re\n",
        "import string\n",
        "thesample1='بورصة مصر تهبط بخسائر سوقية 27 مليار جنيه بضغط مخاوف الضريبة وسط مطالب بالإلغاء'\n",
        "thesample2='يتوقع علماء الفلك لمولود برج الميزان ، خلال الفترة المقبلة، أن يتعرض لمكيدة في العمل من جانب زميل له يشعر بالغيرة تجاهه ويريد ان يخرب علاقته بمديره، لكن سرعان ما تنكشف الأمور'\n",
        "thesample3='موقع الكون - المجموعة الشمسية - حلقات زحل عودة للصفحة الرئيسية - سجل الزوار المجموعة الشمسية - الكواكب وتوابعها - حلقات زحل عودة إلى زحل إضغط على الصورة للتكبير حلقات زحل مع بعض أقماره v حلقات زحل المميزة لهذا الكوكب الجميل بعضها رقيق جدا، مع أن قطرها حوالي 250,000 كيلومتر أو أكثر فهي أقل في السمك من الكيلومتر الواحد في بعض الحلقات وتبلغ سمك بعضها الاخر حوالي 10 كيلومتر ، على الرغم من شكلها الرائع، فإن هناك القليل جدا من المواد فيها، وإذا ضغطت هذه الحلقات في جسم واحد سوف تكون جسم لا يتعدى حجمه أكثر من 100 كيلومتر، ذرات الحلقة هي من الثلج المائي، أو ربما تتكون من ذرات صخرية يغلفها الثلج. أوضحت الصور الملتقطة لحلقات زحلِ انها مكونة من مئات آلالاف من الحلقات، وكذلك مناطقِ الفجوات بين الحلقات تحتوي أيضا على حلقات أضعف. كما ةتشير الدلائل على أن تلك الحلقات هي من جزيئات التي في الغالب من بلورات الثلجِ، وبأحجام قد تكون كبيرة بالأمتار أو صغيرة بالسنتيمترات، أما الكتلة الكلية للحلقات فهي تقدر بكتلة قمر متوسط الحجم. نشؤء الحلقة أصل حلقات زحل مجهولة، مع أنه من الممكن أنها تكونت مع تكون الكوكب نفسه، او ربما انها كانت قمرا ثم أنفجر وتفتت بفعل جاذبية زحل وجذب ذلك الكوكب بقايا الانفجار لتدور في فلكه ، وهناك رأي أخر يقول ان الحلقات ما هي إلا مواد من أقمار زحل نفسه جذبها الكوكب، وأنظمة الحلقة غير مستقرة وهي تتجدد بإستمرار بتأثير العمليات المستمرة، اما المجموعة الحالية للحلقات يحتمل أن تكون بعمر فقط بضعة مئات الملايين من السنين. كان من المتوقع أن الإصطدامات التي تحدث بين جزيئات او مكونات الحلقة هي التي تؤثر على شكل الحلقة. لكن الرحلات الفضائية اوضحت عاملا أخر يؤثر على شكل وترتيب الحلقات وهو عامل التنافر في الشحنات الكهربائية التي تشحن الجزيئات إلى جانب عامل القوة الجذبية . كما اوضحت الاكتشافات التي تمت من خلال رحلة فواجير أن الحلقات ليس من الضروري ان تكون دائرية، كما اكتشف أن الحلقة الخارجيةَ لحلقة ظلت في مكانها بالتفاعل التجاذبي من قمرين صغيرين يقع احدهما داخل الحلقة والاخر خارجها. ترتيب الحلقات تتكون حلقات كوكب زحلِ من خمس حلقات رئيسيةِ هي: G و F و A و B و C مرتبة من الخارج إلى الداخل (في الواقع هذه التقسيماتِ الرئيسيةِ مقسمة إلى آلافِ الحلقات الفرديةِ). الحلقات F و G حلقات رقيقة وصعبة الرؤية، بينما الحلقات الاخرى A و B و C حلقات واسعة وسهلة الرؤية. الفجوة الكبيرة بين الحلقة A و B تسمى قسم كاسيني. الإسم المسافة (كيلومتر) العرض (كم) السمك (كم) البداية النهاية D 66,000 73,150 7,150 C 74,500 92,000 17,500 فاصل ماكسويل ( Maxwell ) 87,500 88,000 500 B 92,000 117,500 25,500 0.1 - 1 قسم كاسيني (Cassini Div) 117,500 122,200 4,700 فاصل فاصل هويجنز ( Huygens ) 117,680 285-440 فاصل فرعي A 122,200 136,800 14,600 0.1 - 1 فاصل إنكي ( Encke ) 133,410 133,740 330 فاصل كيلر ( Keeler ) 136,510 136,550 40 F 140,210 30-500 G 165,800 173,800 8,000 100-1,000 E 180,000 480,000 300,000 1,000 وقد رصد العلماء انفجارا لأوكسجين ذري حول الكوكب، ويدلل ذلك على ان حلقات الكوكب من الممكن أن تتآكل وعلى ذلك يمكن لهذه الحلقات ان تندثر في غضون مئة مليون عام. ويفسر العلماء ان هذا الاوكسجين الذري يشير على وقوع تصادم بين الجسيمات في احدى حلقات الكوكب والتي تتألف من الثلج في معظمها ومن الممكن ان الغاز قد انبعث منها أثناء انشطارها نتيجة التصادم. الحلقة E والتي هي أبعد حلقات زحل وهي حلقة عريضة جدا لكنها ذات إضاءة خافتة تتكون من مواد دقيقة الحجم من الثلج والتراب، تبدأ من مدار القمر ميماس Mimas وتنتهي تقريبا حول مدار القمر ريا Rhea. alnomrosi.net 2005-2006 حقوق النشر متاحة للجميع بشرط ذكر المصدر'\n",
        "thesample='كوكب عطارد من أصغر الكواكب'\n",
        "thesample5='بعد التحقيق مع المجرم المتهم في قتل كل فريقة بمشروع التخرج بسبب كثرة ساعات المزاكرة تم الحكم علية بعشر سنوات من التفاهة'\n",
        "thesample6='هي علاقة السلطة بالمؤسسات، أو علاقة النفوذ في المؤسسات، وتلك العلاقات التي سوف تتم ترجمتها وتحويلها بإعتبرات بيستمولوجية. وتحدث عن مثال لذلك في فرنسا حول العلاقة بين العلوم السياسية والقانونية، فالقانون السياسي أو علم السياسة الفرنسي تطور أولاً في كلية الحقوق، فهناك دائرة القانون العام والعلوم السياسية، وفي لحظة ما من تطور العلوم السياسية أرادت تلك العلوم أن تستقل عن القانون، وبالتالي نشأت علاقات قوة متجاذبة بين دائرة أو كلية الحقوق وبين كلية العلوم السياسية، العلم السياسي أوجد لنفسه مؤسسته الخاصة ومهنته الخاصة بشكل مستقل عن كلية الحقوق، وهذه علاقات القوة تحولت ولكي \"تتحرر\" العلوم السياسية طوّرت تحليلاً للقانون على أنه مادة ليست بذات أهمية، فإن القانون لا يتطرق للمجتمع ولا يتحدث عن السياس'\n",
        "def clean_samples(text):\n",
        "  pattern = r'[0-9]'\n",
        "  pattern2='r[^\\w\\s]'\n",
        "# Match all digits in the string and replace them with an empty string\n",
        "  new_string = re.sub(r'[0-9]', '', text)\n",
        "  new_string=re.sub(r'[^\\w\\s]','',new_string)\n",
        "  new_string = \"\".join([char for char in new_string if char not in string.ascii_letters]).strip()\n",
        "  return new_string.strip()\n",
        "text_clean=clean_samples(thesample)\n",
        "print(text_clean)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "كوكب عطارد من أصغر الكواكب\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY9M9452VSec"
      },
      "source": [
        "import numpy as np\n",
        "def convert_sample_to_numbers(text):\n",
        "  text_result=tfidf_vect.transform([text])\n",
        "  return text_result\n",
        "test=convert_sample_to_numbers(text_clean)\n",
        "#tokens=convert_sample_to_numbers(thesample)\n",
        "\n",
        "#c=clf.predict(np.array(tokens[-1]))    "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCfm43xeZMN6",
        "outputId": "0fc6b4cc-8dab-43ba-f793-b40cc0ee4c2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(encoder.inverse_transform(clf_svm.predict(test)))\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"'فلك-علوم بحتة'\"]\n"
          ]
        }
      ]
    }
  ]
}