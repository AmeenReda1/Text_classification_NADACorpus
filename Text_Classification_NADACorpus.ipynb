{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Classification_NADACorpus",
      "provenance": [],
      "mount_file_id": "https://github.com/AmeenReda1/Text_classification_NADACorpus/blob/main/Text_Classification_NADACorpus.ipynb",
      "authorship_tag": "ABX9TyMkgP2xqVzDFMBPpP9o+v/q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmeenReda1/Text_classification_NADACorpus/blob/main/Text_Classification_NADACorpus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iVsr9ibmeeC"
      },
      "source": [
        "#Text_Classification_NADACorpus\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV22VM2WjNGa"
      },
      "source": [
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm,preprocessing,metrics"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNbdra3ujSJe",
        "outputId": "fe7ee22f-647a-4f70-c300-ceaac90a731d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "dataFrame=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Sampled_File_with_SMOTE.csv')\n",
        "stop=stopwords.words('arabic')\n",
        "print(stop)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['إذ', 'إذا', 'إذما', 'إذن', 'أف', 'أقل', 'أكثر', 'ألا', 'إلا', 'التي', 'الذي', 'الذين', 'اللاتي', 'اللائي', 'اللتان', 'اللتيا', 'اللتين', 'اللذان', 'اللذين', 'اللواتي', 'إلى', 'إليك', 'إليكم', 'إليكما', 'إليكن', 'أم', 'أما', 'أما', 'إما', 'أن', 'إن', 'إنا', 'أنا', 'أنت', 'أنتم', 'أنتما', 'أنتن', 'إنما', 'إنه', 'أنى', 'أنى', 'آه', 'آها', 'أو', 'أولاء', 'أولئك', 'أوه', 'آي', 'أي', 'أيها', 'إي', 'أين', 'أين', 'أينما', 'إيه', 'بخ', 'بس', 'بعد', 'بعض', 'بك', 'بكم', 'بكم', 'بكما', 'بكن', 'بل', 'بلى', 'بما', 'بماذا', 'بمن', 'بنا', 'به', 'بها', 'بهم', 'بهما', 'بهن', 'بي', 'بين', 'بيد', 'تلك', 'تلكم', 'تلكما', 'ته', 'تي', 'تين', 'تينك', 'ثم', 'ثمة', 'حاشا', 'حبذا', 'حتى', 'حيث', 'حيثما', 'حين', 'خلا', 'دون', 'ذا', 'ذات', 'ذاك', 'ذان', 'ذانك', 'ذلك', 'ذلكم', 'ذلكما', 'ذلكن', 'ذه', 'ذو', 'ذوا', 'ذواتا', 'ذواتي', 'ذي', 'ذين', 'ذينك', 'ريث', 'سوف', 'سوى', 'شتان', 'عدا', 'عسى', 'عل', 'على', 'عليك', 'عليه', 'عما', 'عن', 'عند', 'غير', 'فإذا', 'فإن', 'فلا', 'فمن', 'في', 'فيم', 'فيما', 'فيه', 'فيها', 'قد', 'كأن', 'كأنما', 'كأي', 'كأين', 'كذا', 'كذلك', 'كل', 'كلا', 'كلاهما', 'كلتا', 'كلما', 'كليكما', 'كليهما', 'كم', 'كم', 'كما', 'كي', 'كيت', 'كيف', 'كيفما', 'لا', 'لاسيما', 'لدى', 'لست', 'لستم', 'لستما', 'لستن', 'لسن', 'لسنا', 'لعل', 'لك', 'لكم', 'لكما', 'لكن', 'لكنما', 'لكي', 'لكيلا', 'لم', 'لما', 'لن', 'لنا', 'له', 'لها', 'لهم', 'لهما', 'لهن', 'لو', 'لولا', 'لوما', 'لي', 'لئن', 'ليت', 'ليس', 'ليسا', 'ليست', 'ليستا', 'ليسوا', 'ما', 'ماذا', 'متى', 'مذ', 'مع', 'مما', 'ممن', 'من', 'منه', 'منها', 'منذ', 'مه', 'مهما', 'نحن', 'نحو', 'نعم', 'ها', 'هاتان', 'هاته', 'هاتي', 'هاتين', 'هاك', 'هاهنا', 'هذا', 'هذان', 'هذه', 'هذي', 'هذين', 'هكذا', 'هل', 'هلا', 'هم', 'هما', 'هن', 'هنا', 'هناك', 'هنالك', 'هو', 'هؤلاء', 'هي', 'هيا', 'هيت', 'هيهات', 'والذي', 'والذين', 'وإذ', 'وإذا', 'وإن', 'ولا', 'ولكن', 'ولو', 'وما', 'ومن', 'وهو', 'يا']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFwKrhZVkJ4L",
        "outputId": "c9db0728-be1c-49de-8f18-a962f3f08c74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Length before remove duplicate: ',len(dataFrame))\n",
        "dataFrame.drop_duplicates(subset =\"text\", keep = 'first', inplace = True)\n",
        "print('Length before remove duplicate: ',len(dataFrame))\n",
        "dataFrame['text']=dataFrame['text'].apply(lambda line: \" \".join(word for word in line.split() if word not in stop))\n",
        "print(dataFrame.head())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length before remove duplicate:  13066\n",
            "Length before remove duplicate:  5745\n",
            "                                                text                     class\n",
            "0  'غالبيت اصول اعمال باقرب ست رحب دولار اختصارا ...  'الإقتصاد-علوم اجتماعية'\n",
            "1  'اضافت اخير بنك دول مال رئيس اعمال يقلص افق لا...  'الإقتصاد-علوم اجتماعية'\n",
            "2  'مستقره اضافت اخير دول اتفاق اعمال يقلص افق لا...  'الإقتصاد-علوم اجتماعية'\n",
            "3  'اوسط سرق بنك عاما ثان متحده مخبرا لملا الفضول...  'الإقتصاد-علوم اجتماعية'\n",
            "4  'اوسط اطول عاما ثان متحده بان مخبرا لملا اعمال...  'الإقتصاد-علوم اجتماعية'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FpHx97akNlv",
        "outputId": "ea646d2e-3d24-48a4-c787-f6c19a84f8e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_x, valid_x, train_y, valid_y = train_test_split(dataFrame['text'], dataFrame['class'],test_size=0.2)\n",
        "print(len(set(train_y)))\n",
        "print(len(set(valid_y)))\n",
        "# TFIDF feature generation for a maximum of 5000 features\n",
        "print(\"vaild X\",valid_x.head())\n",
        "print(\"vaild X\",valid_y.head())\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word',token_pattern=r'\\w{1,}', max_features=5000)\n",
        "print(tfidf_vect)\n",
        "tfidf_vect.fit(dataFrame['text'])\n",
        "xtrain_tfidf = tfidf_vect.transform(train_x)\n",
        "xvalid_tfidf = tfidf_vect.transform(valid_x)\n",
        "print(xtrain_tfidf.data)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "10\n",
            "vaild X 97      'مشاريع مشروع امال يذكر مشارك دمرت اجل اعاد خم...\n",
            "4304    'كشف سيد علا محام بمركز هشام مبارك عضو مجلس ام...\n",
            "4734    'مصدر قائم متنافس طب ارسل تساعد اختيار حرار اي...\n",
            "4857    'بحرك رحبت اصابتهم مخ فبراير فقط مصاب اجاب انغ...\n",
            "6740    'تاجيل عدل انسانيت يتصور ممارس لاعدال عادل معك...\n",
            "Name: text, dtype: object\n",
            "vaild X 97      'الإقتصاد-علوم اجتماعية'\n",
            "4304     'القانون-علوم اجتماعية'\n",
            "4734    'علوم صحية-علوم تطبيقية'\n",
            "4857    'علوم صحية-علوم تطبيقية'\n",
            "6740     'القانون-علوم اجتماعية'\n",
            "Name: class, dtype: object\n",
            "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
            "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
            "                input='content', lowercase=True, max_df=1.0, max_features=5000,\n",
            "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
            "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
            "                sublinear_tf=False, token_pattern='\\\\w{1,}', tokenizer=None,\n",
            "                use_idf=True, vocabulary=None)\n",
            "[0.04693678 0.04419341 0.06150374 ... 0.08043109 0.0780783  0.08681923]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmsBVwGokQrx"
      },
      "source": [
        "def train_model(classifier, feature_vector_train, label,feature_vector_valid, is_neural_net=False):\n",
        "    # fit the training dataset on the classifier\n",
        "    classifier.fit(feature_vector_train, label)\n",
        "    # predict the labels on validation dataset\n",
        "    predictions = classifier.predict(feature_vector_valid)\n",
        "    return metrics.accuracy_score(predictions, valid_y),predictions"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2NvOFoNkTx9",
        "outputId": "3eda14a1-9faa-44d1-94ec-387d51a50685",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "clf = svm.SVC(kernel='linear')\n",
        "#train_model\n",
        "accuracy,predictions=train_model(clf,xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print(\"accuracy: \",accuracy*100)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  98.43342036553526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Hns-gzgkYeE",
        "outputId": "d6c8d8ac-1afb-434e-b510-89fee5b7b467",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(valid_y,predictions))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.94      0.96        72\n",
            "           1       0.99      1.00      0.99       250\n",
            "           2       0.85      0.81      0.83        21\n",
            "           3       0.98      0.98      0.98       256\n",
            "           4       0.98      1.00      0.99        51\n",
            "           5       1.00      0.97      0.98        62\n",
            "           6       1.00      1.00      1.00        84\n",
            "           7       0.99      0.99      0.99        67\n",
            "           8       1.00      0.99      1.00       186\n",
            "           9       0.96      0.99      0.98       100\n",
            "\n",
            "    accuracy                           0.98      1149\n",
            "   macro avg       0.97      0.97      0.97      1149\n",
            "weighted avg       0.98      0.98      0.98      1149\n",
            "\n"
          ]
        }
      ]
    }
  ]
}